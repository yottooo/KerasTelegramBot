{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "from keras import backend as K\n",
    "from keras.utils import generic_utils\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input,Dropout ,Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#For plotting the evaluations\n",
    "import matplotlib.pyplot as plt\n",
    "#Pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "###\n",
    "# normalize contractions\n",
    "# @param string string to normalize\n",
    "# @return normalized string\n",
    "###\n",
    "def normalize_contractions(string):\n",
    "    contractions = {\n",
    "        \"i'm\": \"i am\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"w/\": \"with\",\n",
    "        \" w \": \"with\",\n",
    "        \":\\)\": \"\",\n",
    "        \":\\(\": \"\"\n",
    "    }\n",
    "    for k, v in contractions.items():\n",
    "        string = string.replace(k, v)\n",
    "    return string\n",
    "\n",
    "###\n",
    "# remove non ascii chars (especially to remove emojis)\n",
    "# @param string string to perform removal on\n",
    "# @return string without ascii chars\n",
    "###\n",
    "def remove_non_ascii(string): # especially emojis, attn with foreign languages (but they are not considered here)\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', string)\n",
    "\n",
    "###\n",
    "# remove rt (retweet mentions)\n",
    "# @param string string to perform removal on\n",
    "# @return string without rt\n",
    "###\n",
    "def remove_rt(string): # remove rt incl. user mention (RT to colon)\n",
    "    return re.sub('RT \\@+\\w+:\\s', '', string)\n",
    "\n",
    "###\n",
    "# remove user mentions except at @...\n",
    "# @param string string to perform removal on\n",
    "# @return string without user mention\n",
    "###\n",
    "def remove_usermentions(string): # WITHOUT \"at @...\" because it may refer to company name!!!\n",
    "    return re.sub('/(?<!at )\\@+\\w+/g', '', string)\n",
    "\n",
    "###\n",
    "# remove url\n",
    "# @param string string to perform removal on\n",
    "# @return string without url\n",
    "###\n",
    "def remove_url(string):\n",
    "    return re.sub('http\\S+', '', string)   \n",
    "\n",
    "###\n",
    "# remove hashtags\n",
    "# @param string string to perform removal on\n",
    "# @return string without hashtags\n",
    "###\n",
    "def remove_hashtags(string):\n",
    "    return re.sub('\\#\\S+ *', '', string)\n",
    "\n",
    "# perform preprocessing steps by running related methods\n",
    "# @return preprocessed dataframe\n",
    "###\n",
    "def preprocess_dataset(df):\n",
    "    df_to_return = df\n",
    "    for i in df_to_return.index:\n",
    "        df_to_return.at[i, 1] = remove_hashtags(df_to_return.at[i, 1])\n",
    "        df_to_return.at[i, 1] = normalize_contractions(df_to_return.at[i, 1])\n",
    "        df_to_return.at[i, 1] = remove_non_ascii(df_to_return.at[i, 1])\n",
    "        df_to_return.at[i, 1] = remove_rt(df_to_return.at[i, 1])\n",
    "        df_to_return.at[i, 1] = remove_usermentions(df_to_return.at[i, 1])\n",
    "        df_to_return.at[i, 1] = remove_url(df_to_return.at[i, 1])\n",
    "    return df_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to compute fmeasure by keras team github repository, cf. https://github.com/keras-team/keras/blob/1c630c3e3c8969b40a47d07b9f2edda50ec69720/keras/metrics.py\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "\n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis=-1),\n",
    "                          K.argmax(y_pred, axis=-1)))\n",
    "\n",
    "\n",
    "def sparse_categorical_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.max(y_true, axis=-1),\n",
    "                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())))\n",
    "\n",
    "\n",
    "def top_k_categorical_accuracy(y_true, y_pred, k=5):\n",
    "    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k))\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n",
    "                                            K.epsilon(),\n",
    "                                            None))\n",
    "    return 100. * K.mean(diff)\n",
    "\n",
    "\n",
    "def mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.mean(K.square(first_log - second_log))\n",
    "\n",
    "\n",
    "def hinge(y_true, y_pred):\n",
    "    return K.mean(K.maximum(1. - y_true * y_pred, 0.))\n",
    "\n",
    "\n",
    "def squared_hinge(y_true, y_pred):\n",
    "    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))\n",
    "\n",
    "\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.categorical_crossentropy(y_pred, y_true))\n",
    "\n",
    "\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.sparse_categorical_crossentropy(y_pred, y_true))\n",
    "\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_pred, y_true))\n",
    "\n",
    "\n",
    "def kullback_leibler_divergence(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))\n",
    "\n",
    "\n",
    "def poisson(y_true, y_pred):\n",
    "    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()))\n",
    "\n",
    "\n",
    "def cosine_proximity(y_true, y_pred):\n",
    "    y_true = K.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = K.l2_normalize(y_pred, axis=-1)\n",
    "    return -K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    \"\"\"Matthews correlation metric.\n",
    "\n",
    "    It is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    Computes the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    \"\"\"\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "# aliases\n",
    "mse = MSE = mean_squared_error\n",
    "mae = MAE = mean_absolute_error\n",
    "mape = MAPE = mean_absolute_percentage_error\n",
    "msle = MSLE = mean_squared_logarithmic_error\n",
    "cosine = cosine_proximity\n",
    "fscore = f1score = fmeasure\n",
    "\n",
    "\n",
    "def get(identifier):\n",
    "    return get_from_module(identifier, globals(), 'metric')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe\n",
    "df = pd.read_csv(\"extended_training_set.csv\", sep='\\t', header=None,error_bad_lines=False)\n",
    "df = preprocess_dataset(df)\n",
    "# split test set\n",
    "texts = df[1]\n",
    "labels = df[0]\n",
    "\n",
    "MAX_NB_WORDS = 5000 # consider to 5,000 most occuring words in dataset\n",
    "MAX_SEQUENCE_LENGTH = 1000 # truncate sequences to a maximum length of 1000 words\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "#Set embeding layer to trainable\n",
    "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "# 3 hidden layers with 128 neurons each\n",
    "x = Conv1D(64, 5, activation='relu')(embedded_sequences)\n",
    "x = Dropout(0.5)(x) #add Regularization\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x) # 2 ... binary\n",
    "#Instantiate model\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics= ['acc'])\n",
    "\n",
    "# 20 epochs fit the data on the model\n",
    "model_hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evaluation metrics and epochs Accuracy\n",
    "acc = model_hist.history['acc']\n",
    "val_acc = model_hist.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training Accuracy.')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy.')\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Training and validation accuracy.')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evaluation metrics and epochs Loss\n",
    "loss = model_hist.history['loss']\n",
    "val_loss = model_hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') # bo ... blue dot\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss.')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13074 unique tokens.\n",
      "18846/18846 [==============================] - 48s 3ms/step\n",
      "[0.9827842817531198, 0.48201209806110606]\n"
     ]
    }
   ],
   "source": [
    "# perform prediction on test set\n",
    "df = pd.read_csv(\"expl_18k.csv\", sep='\\t', header=None)\n",
    "\n",
    "texts = df[1]\n",
    "labels = df[0]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sequences= tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(labels)\n",
    "prediction = model.predict(data, batch_size=10)[0,1]\n",
    "prediction1 = model.evaluate(data, labels, verbose=1)\n",
    "#print(prediction)\n",
    "print(prediction1) # loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Twitter\n",
    "from twython import Twython\n",
    "from twython import TwythonStreamer\n",
    "\n",
    "from twitter import *\n",
    "APP_KEY=\"Your keys\"\n",
    "APP_SECRET=\"\"\n",
    "OAUTH_TOKEN=\"\"\n",
    "OAUTH_TOKEN_SECRET=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamer(TwythonStreamer): \n",
    "    def on_success(self, data): \n",
    "        if 'text' in data:\n",
    "            sequences= tokenizer.texts_to_sequences([data['text']])\n",
    "            dat = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "            prediction = model.predict(dat, batch_size=64)[0,1]\n",
    "\n",
    "            if prediction >0.8:\n",
    "                print(data['text'])\n",
    "                print(prediction)\n",
    "\n",
    "def on_error(self, status_code, data):\n",
    "    print(status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = MyStreamer(APP_KEY, APP_SECRET,\n",
    "                    OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "stream.statuses.filter(track='Hirring , Job , CareerArc ',language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'x1.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename = 'x1.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "import tensorflow as tf\n",
    "global graph\n",
    "graph = tf.get_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
